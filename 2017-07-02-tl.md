---
layout: post
comments: true
title:  "Quick Note 2: Transfer Learning cho bài toán phân loại ảnh"
title2:  "Q2. Transfer Learning"
date:   2017-07-02 15:22:00
permalink: 2017/07/02/tl/
mathjax: true
tags: Feature-engineering Classification DeepLearning Quick-Notes
category: Deep-Learning 
sc_project: 11384680
sc_security: 5890851e
img: /assets/q2_tl/multi_layers.png
summary: Ghi chú nhanh về việc sử dụng các pretrained models cho bài toán phân loại ảnh. Phương pháp này được gọi là Transfer Learning. 
---



Trước Deep Learning, bài toán phân loại ảnh (các loại dữ liệu khác cũng tương tự) thường được chia thành 2 bước: Feature Engineering và Train a Classifier. Hai bước này thường được tách rời nhau. Với Feature Engineering, các phương pháp thường được sử dụng cho ảnh là [SIFT](http://docs.opencv.org/3.1.0/da/df5/tutorial_py_sift_intro.html) (Scale Invariant Feature Transform), [SURF](http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_feature2d/py_surf_intro/py_surf_intro.html) (Speeded-Up Robust Features), [HOG](http://www.learnopencv.com/histogram-of-oriented-gradients/) (Histogram of Oriented Gradients), LBP (Local Binary Pattern), etc. Các Classifier thường được sử dụng là [multi-class SVM](/2017/04/28/multiclasssmv/), [Softmax Regression](/2017/02/17/softmax/), Discriminative Dictionary Learning, Random Forest, etc.

Các phương pháp Feature Engineering nêu trên thường được gọi là các _hand-crafted features_ (feature được tạo thủ công) vì nó chủ yếu dựa trên các quan sát về đặc tính riêng của ảnh. Các phương pháp này cho kết quả khá ấn tượng trong một số trường hợp. Tuy nhiên, chúng vẫn còn nhiều hạn chế vì quá trình tìm ra các features và các classifier phù hợp vẫn là riêng biệt.

(Tôi đã từng đề cập tới vấn đề này trong [các mô hình end-to-end](/2017/04/28/multiclasssmv/#-mo-hinh-end-to-end))

Những năm gần đây, Deep Learning phát triển cực nhanh dựa trên lượng dữ liệu training khổng lồ và khả năng tính toán ngày càng được cải tiến của các máy tính. Các kết quả cho bài toán phân loại ảnh ngày càng được nâng cao. Bộ cơ sở dữ liệu thường được dùng nhất là [ImageNet](https://www.image-net.org) với 1.2M ảnh cho 1000 classes khác nhau. Rất nhiều các mô hình Deep Learning đã giành chiến thắng trong các cuộc thi [ILSVRC](https://www.google.com/search?client=opera&q=imagenet+results&sourceid=opera&ie=UTF-8&oe=UTF-8#q=ILSVRC+) (ImageNet Large Scale Visual Recognition Challenge). Có thể kể ra một vài: [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf), [ZFNet](https://www.cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf), [GoogLeNet](https://arxiv.org/abs/1409.4842v1), [ResNet](https://arxiv.org/pdf/1502.01852.pdf), [VGG](https://www.robots.ox.ac.uk/~vgg/research/very_deep/).

<hr>
<div class="imgcap">
<img src ="/assets/q2_tl/multi_layers.png" align = "center" width = "500">
</div>

<div class = "thecap" style = "text-align: justify" >Hình 1: Mô hình chung cho các bài toán classification sử dụng Deep Learning. Layer cuối cùng thường là một Fully Connected Layer và thường là một Softmax Regression.</div>
<hr>

Nhìn chung, các mô hình này đều bao gồm rất nhiều layers. Các layers phía trước thường là các Convolutional layers kết hợp với các nonlinear [activation functions](/2017/02/24/mlp/#-activation-functions) và pooling layers (và được gọi chung là ConvNet). Layer cuối cùng là một Fully Connected Layer và thường là một Softmax Regression (Xem Hình 1). Số lượng units ở layer cuối cùng bằng với số lượng classes (với ImageNet là 1000). Vì vậy output ở layer gần cuối cùng (second to last layer) có thể được coi là feature vectors và Softmax Regression chính là Classifier được sử dụng.

Chính nhờ việc features và classifier được trained cùng nhau qua deep networks khiến cho các mô hình này đạt kết quả tốt. Tuy nhiên, những mô hình này đều là các Deep Networks với rất nhiều layers. Việc training dựa trên 1.2M bức ảnh của ImageNet cũng tốn rất nhiều thời gian (2-3 tuần).

Với các bài toàn dựa trên tập dữ liệu khác, rất ít khi người ta xây dựng và train lại toàn bộ Network từ đầu, bởi vì có rất ít các cơ sở dữ liệu có kích thước lớn. Thay vào đó, phương pháp thường được dùng là sử dụng các mô hình (nêu phía trên) đã được trained từ trước, và sử dụng một vài kỹ thuật khác để giải quyết bài toán. Phương pháp sử dụng các mô hình có sẵn như thế này được gọi là _Transfer Learning_.

Như đã đề cập, toàn bộ các layer trừ output layer có thể được coi là một bộ Feature Extractor. Dựa trên nhận xét rằng các bức ảnh đều có những đặc tính giống nhau nào đó, với cơ sở dữ liệu khác, ta cũng có thể sử dụng phần Feature Extractor này để tạo ra các feature vectors. Sau đó, ta thay output layer cũng bằng một Softmax Regression (hoặc multi-class SVM) nhưng với số lượng units bằng với số lượng class ở bộ cơ sở dữ liệu mới. Ta chỉ cần train layer cuối cùng này. Kinh nghiệm thực tế của tôi cho thấy, việc làm này đã tăng kết quả phân lớp lên rất nhiều so với việc sử dụng các _hand-crafted features_.

Cách làm như trên được gọi là __ConvNet as fixed feature extractor__, tức ta sử dụng trực tiếp vector ở _second to last layer_ làm feature vector. Nếu tiếp tục tinh chỉnh (Fine-tuning) một chút nữa, kết quả sẽ có thể tốt hơn.

__Fine-tuning the ConvNet__. Hướng tiếp cận thứ hai là sử dụng các weights đã được trained từ một trong các mô hình ConvNet như là khởi tạo cho mô hình mới với dữ liệu mới và sử dụng [Back Propagation](/2017/02/24/mlp/#-backpropagation) để train lại toàn bộ mô hình mới hoặc train lại một số layer cuối (cũng là để tránh [overfitting](/2017/03/04/overfitting/) khi mà mô hình quá phức tạp khi dữ liệu không đủ lớn). _Việc này được dựa trên quan sát rằng những layers đầu trong ConvNet thường giúp extract những đặc tính chung của ảnh (các cạnh - edges, còn được gọi là low-level features), các layers cuối thường mang những đặc trưng riêng của cơ sở dữ liệu (CSDL) (và được gọi là high-level features). Vì vậy, việc train các layer cuối mang nhiều giá trị hơn._

Dựa trên kích thước và độ tương quan giữa CSDL mới và CSDL gốc (chủ yếu là ImageNet) để train các mô hình có sẵn, [CS231n đưa ra một vài lời khuyên](http://cs231n.github.io/transfer-learning/#tf):

* _CSDL mới là nhỏ và tương tự như CSDL gốc._ Vì CSDL mới nhỏ, việc tiếp tục train model dễ dẫn đến hiện tượng overfitting. Cũng vì hai CSDL là tương tự nhau, ta dự đoán rằng các high-level features là tương tự nhau. Vậy nên ta không cần train lại model mà chỉ cần train một classifer dựa trên feature vectors ở đầu ra ở layer gần cuối.

* _CSDL mới là lớn và tương tự như CSDL gốc._ Vì CSDL này lớn, overfitting ít có khả năng xảy ra hơn, ta có thể train mô hình thêm một chút nữa (toàn bộ hoặc chỉ một vài layers cuối).

* _CSDL mới là nhỏ và rất khác với CSDL gốc._ Vì CSDL này nhỏ, tốt hơn hết là dùng các classifier đơn giản (các linear classifiers) để tránh overfitting). Nếu muốn train thêm, ta cũng chỉ nên train các layer cuối. Hoặc có một kỹ thuật khác là coi đầu ra của một layer xa layer cuối hơn làm các feature vectors.

* _CSDL mới là lớn và rất khác CSDL gốc._ Trong trường hợp này, ta vẫn có thể sử dụng mô hình đã train như là điểm khởi tạo cho mô hình mới, không nên train lại từ đầu.

Có một điểm đáng chú ý nữa là khi tiếp tục train các mô hình này, ta chỉ nên chọn _learning rate_ nhỏ để các weights mới không đi quá xa so với các weights đã được trained ở các mô hình trước.




<a name="tai-lieu-tham-khao"></a>

## Đọc thêm
[1] [Introduction to SIFT (Scale-Invariant Feature Transform) - OpenCV](http://docs.opencv.org/3.1.0/da/df5/tutorial_py_sift_intro.html)

[2] [Introduction to SURF (Speeded-Up Robust Features) - OpenCV](Introduction to SURF (Speeded-Up Robust Features))

[3] [Histogram of Oriented Gradients - OpenCV](http://www.learnopencv.com/histogram-of-oriented-gradients/)

[4] [Transfer Learning](http://cs231n.github.io/transfer-learning/#tf)

[5] [Transfer Learning - Machine Learning's Next Frontier](http://sebastianruder.com/transfer-learning/)

[6] [Transfer learning & The art of using Pre-trained Models in Deep Learning](https://www.analyticsvidhya.com/blog/2017/06/transfer-learning-the-art-of-fine-tuning-a-pre-trained-model/)
